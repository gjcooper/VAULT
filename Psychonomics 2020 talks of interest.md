# Psychonomics 2020 talks and notes

## Talks

### MathPsych Satellite Meeting

#### Using Discrete Recurrence Quantification Analysis to Probe the Dynamics of Decision Making

Leslie Blaha

The use of Recurrence Quanitification Analysis for decision making was
quite fascinating. The example used to illustrate was a gambling style
task with either a staionary reward or a non-stationary reward, and the
win-stay-lose-shift strategy was compared to human performance using
these techniques.

Perhaps this kind of analysis could be used to look at the possible
decision strategies employed in the preference and veridical tasks that
I have been running.

Refs:

1.  McCormick, E. N., Blaha, L. M. & Gonzalez, C. Exploring Dynamic
    Decision Making Strategies with Recurrence Quantification Analysis.
    3041–3047 (2020).
2.  Coco, M. I. & Dale, R. Cross-recurrence quantification analysis of
    categorical and continuous time series: An R package. Front.
    Psychol. 5, 1–14 (2014).

### Cognition: Decision Making

#### 166 - RT Bank: An Online Repository for Reaction Time Data and Models

*Time models are used to analyze data from RT tasks, offering advantages
over traditional analyses based on RTs or error rates. Newer versions of
these models are also being developed to expand their usage to data from
tasks of executive function. To increase use of these models in domains
like clinical or developmental psychology we need to ensure they are
validated and accessible. To that end, we have developed the RT Bank
(rtbank.missouriwestern.edu), an online repository for researchers to
upload and download RT data for model comparison and validation, and RT
models to use for analyzing their own data. The website was purposefully
designed to be minimalistic, allowing researchers to upload data and
models in various formats along with accompanying detailed readme files.
We discuss the framework and capabilities of the RT Bank with focus on
improvements to best serve the needs of researchers working with RT
models.*

COREY WHITE, GAVIN WATERS, and RHIMMON SIMCHY-GROSS, Missouri Western
State University (cwhite34@missouriwestern.edu)

Interesting concept, maybe a bit too loose in terms of organisation
structure. Have registered, does not seem to have anything, will check
again in a few days.

#### 197 - Do You Want to Know a Secret? Factors Affecting the Pursuit of Non-Instrumental Information

*Most standard economic and psychological theories posit that
information should only be valued to the extent that it informs a
decision-maker and facilitates obtaining a desired outcome. Despite
this, several recent studies appear to demonstrate that there is an
intrinsic value to information even when it cannot be used to guide
future behaviour. We investigate participants’ preferences to ‘find out’
or ‘keep secret’ information about an imminent but predetermined
outcome. We examine the impact of outcome-type (primary vs. secondary
reinforcers), outcome-valence (positive vs. negative) and the delay
between a predictive cue and outcome-receipt on this preference for
‘useless’ information. We find that the tendency to seek
non-instrumental information increases with delay but only for primary
reinforcers and irrespective of whether they are positive (e.g.,
chocolate) or negative (e.g. aversive sounds). We discuss the results in
terms of a computational account which incorporates anticipatory
utility, temporal discounting and uncertainty aversion.*

Jake Embrey Shi-Xian Liew Ben Newell, UNSW Sydney

Models of delay discounting with non-instrumental information.

### Statistics and Methodology

#### 169 - Computational Models Enhance Test-Retest Reliability of Behavioral Measures of Individual Differences

*A number of behavioral tasks that produce robust experimental effects
have recently been criticized for having undesirable psychometric
properties, such as poor test-retest reliability. These conclusions
arise due to the heuristic methods that researchers use to analyze
behavioral data, which systematically ignore critical sources of
measurement error. To correct this, we describe generative models and
hierarchical Bayesian analyses that allow us to more precisely estimate
individual differences from behavioral data. Using both simulations and
empirical data collected from the Stroop, Flanker, Posner Cueing,
Implicit Association, and Delay Discounting tasks, we show that these
generative models result in both: (1) higher test-retest reliability
estimates, and (2) more theoretically informative parameter estimates
relative to traditional approaches. Our results invoke optimism
regarding the ability of behavioral paradigms to reliably assess
individual differences, and emphasize the importance of rigorous
quantitative (and generative) models for making valid statistical
inferences.*

Brandon Turner Peter Kvam, University of Florida Nathaniel Haines, The
Ohio State University

Might be helpful to reach out to Peter/Nathaniel about the PMwG package
as it seems it might be helpful for fitting some of the more advaced
models in a hierarchical bayesian way.

#### 170 - How Do We Choose our Giants? Perceptions of Replicability in Psychological Science

*Judgments regarding replicability are vital to scientific progress. The
metaphor of “standing on the shoulders of giants” highlights that
progress is made when new discoveries build on prior findings. This
process operates most efficiently when the findings being built on are
replicable. In this registered report, we examine how psychological
scientists evaluate the replicability of a research finding. We surveyed
700 corresponding authors of recent articles in psychology journals,
asking them to consider 76 specific study attributes that might bear
upon the replicability of a finding (e.g., preregistration, sample size,
statistical methods). Participants were asked to rate the extent to
which information regarding each attribute increases or decreases their
confidence in the finding replicating. Our results show that certain
factors influenced perceptions of replicability in a consistent manner
(e.g., higher power increasing perceived replicability), whereas other
factors produced inconsistent responses across participants (e.g.,
preregistration). By shedding light on the perceived efficacy of certain
research practices, these findings can inform discussions around how to
improve the robustness of psychological research.*

David Sewell Raine Vickers-Jones Manikya Alister Timothy Ballard, The
University of Queensland

Interesting look at what people take into consideration when viewing
whether some published research may be replicable. Introduction to me on
how the factor analysis bayesFM could perhaps be applied.

#### 171 - Theories are True or False, But Underlying Effect Sizes Are Continuous

*The goal of scientific research is to generate knowledge and publish
authentic discoveries (i.e., true positives). A true positive refers to
a significant finding for which the underlying effect size (?) is
greater than 0, whereas a false positive refers to a significant finding
for which ? = 0, despite the significant outcome. However, the null
hypothesis of no difference (? = 0) is rarely if ever true because of
minor (and therefore overlooked) methodological artifacts. Thus, with
sufficient power, virtually every experiment would yield a significant
result. Yet running studies with higher power to minimize false
positives is perhaps the most widely agreed upon reform to address the
apparent replication crisis. Despite its intuitive appeal, focusing on
reducing scientific false positives at the level of the underlying
effect size (i.e., minimizing significant results despite ? = 0) will
have to the unintended consequence of increasing false positives at the
level of theory (i.e., significant results despite false theoretical
claims). The appropriate but almost never considered goal is to conduct
scientific research in such a way as to maximize the ability to
discriminate true theoretical claims from false theoretical claims.*

John Wixted Christine Harris Brent Wilson, University of California, San
Diego

Nice way to think about true positives and false positives, in
particular effect sizes and what they mean at the level of theories.

## Posters

### Attention

#### 1052 - Some Assembly Required: Examining Strategy Use During Multi-Modal Search for LEGO Bricks

Poster - Jessica Madrid et al

Comparison of strategies during a multimodal search task (Looking for
Lego bricks andable to use their hands). Participants were instructed to
use either an Active of Passive strategy, with differnces in response
times apparent (Speed/Accuracy).

Perhaps this data could be modelled with LBA?

Refs: Paper under review: Multi-modal search: examining strategy use
during search for lego bricks

#### 1024 - Preparing to Select: Preparatory Influences on Selective Attention in a Two-Target Method.

*We examined whether preparatory processes can produce selection history
effects in a selective attention task. We used a two-target attentional
blink task in which participants identified two rapidly presented target
items—a red target word spatially interleaved with a green distractor
word (T1), followed by a single white word (T2; MacLellan, Shore, &
Milliken, 2015). Prior to T1, a coloured word (T0) was presented. Asking
participants to selectively name only red T0 words significantly
improved T2 identification performance, whereas having participants name
any T0 word did not (even if T0 was red). These results imply that a
history of preparing attention in a particular way can modify
attentional templates that mediate selective attention efficiency. We
discuss our findings in the context of selection history effects and
associative learning theories of cognitive control.*

Not of particular relevance to me, but the talk was a great discussion
about selective attention.

### Cognition

\==== 1063 - A Solution to the Feature Binding Problem for Risky
Choice.====

*Sequential sampling models predict attention, choice, and response time
in simple preferential choice, but are typically unable to handle more
complex settings, such as those involving multi-branch gambles. To make
reasonable decisions for such gambles, decision makers need to multiply
payoffs against their corresponding probabilities, which cannot be
accomplished by models that sample and integrate evidence additively.
This is analogous to the feature binding problem in cognitive science,
which involves the integration of perceptual properties in object
representation. In this paper, we provide a solution to the feature
binding problem for risky choice. We propose an interactive sampling
mechanism according to which the likelihood of sampling a payoff depends
on its associated probability. We show that this mechanism allows
sequential sampling models to make utility-maximizing decisions. In six
eye-tracking and mouse-tracking experiments, we find that most
participants display interactive sampling, and that stronger interactive
sampling is associated with more utility-maximizing choices on the
participant-level. Overall, our results show how interactive sampling
can be used to generate and predict sophisticated risky decisions.*

Interesting concept, need to view more detail to see how relevant it is.
Not clear how the eye tracking was involved.

#### 1072 - The Effect of Numeric Uncertainty Information on Complex Decision Making.

*Previous research suggests that people are able to make better
decisions and have higher trust in forecast information with numeric
uncertainty estimates (e.g. probabilities) when compared to
deterministic forecasts. However, most of the previous studies used a
binary decision task, to take protective action at a cost or not,
risking a larger loss. However, most real-world situations include
intermediate options. The present study aims to determine whether the
above-mentioned advantages for probabilistic forecasts are observed in a
more complex decision situation with an intermediate option. To
investigate this, a school closure decision task with three options
(closing, delaying, remaining open) was compared to a binary two option
decision task (closing, remaining open). Half of participants received
probabilistic, and the other half received deterministic forecasts.
Preliminary results suggest that the advantages for probabilistic
forecasts hold across task complexity although performance declined with
more options. Implications will be discussed.*

Very global levels of decision making analysis, no modelling.
Interesting to see how other pople approach decision making research.

#### 1077 - Complexity Aversion in Risk Preferences.

*Decision environments have become increasingly complex with an
ever-increasing amount of information available to inform our decisions.
However, it remains unclear if and how complexity alters risk
preferences. Previous research investigating this relationship revealed
somewhat conflicting results, with some research finding complexity
aversion and others finding complexity neutrality. We address these
conflicting results by investigating the effect of complexity on risk
preferences in two studies (overall n = 423). Our results reveal that
complexity aversion is format dependent (judgment-choice gap) and most
likely stems from an avoidance of cognitive effort. In support of this,
cognitive ability was an important moderator of the effect and process
measures of participant cognitive effort correlated negatively with the
effect. Moreover, the results indicate that complexity increases the
noise in the decision process, a mechanism that can seemingly amplify
the effect in asymmetric choices designs. These results have important
implications for experiment designs in risky choice and judgment and
should inform cognitive models and the comparative study of groups
differing in cognitive ability (e.g. age effects).*

Complexity aversion prominent for those indexed as lower in cognitive
ability (unsure of the measure).

#### 1079 - Does Looking Mean Liking? Processing Differences Across Perceptual and Preferential Choice.

*In perceptual decision making, attention boosts discrimination by
enhancing early visual information processing. Yet, in preferential
decision making people tend to choose the option they attend to the most
implying attention may bias performance. So does selective attention
improve decision discrimination, bias choice, or both? To address this
question, we compared perceptual and preferential choice with an eye
tracking-coupled experience-based paradigm. Participants chose between
two rapidly updating “fishing ponds” by either making a preferential
choice (identify the pond they would like to fish from) or a perceptual
choice (identify the pond with the most fish). Results from two studies
show that selective attention tends to bias choice and that this bias is
greater for preferential choice. The bias arises because selective
attention shapes the accumulated evidence. If people allocate attention
more equally, then the bias dissipates for both perceptual and
preferential choice.*

Tests the different interpretations of gaze affecting decision making in
preferential vs perceptual decision making. Interesting framing for a
random dot motion task (fish in pond?). Should look up the gaze cascade
effect for my eye tracking research.

#### 1082 - When are People Sensitive to Information Dependency in Judgments Under Uncertainty?

*Judgments under uncertainty often rely on advice from multiple social
sources. We examined how such judgments are affected by advice from
multiple independent sources compared with “dependent” sources, where
advice supplied by one source influences others. Ten experiments used a
modified-balls-and urns task where participants judged which of two
colored urns had been randomly selected, after hearing guesses from
several informants. Informants provided independent testimony based
solely on their own observations, or sequential testimony, which
considered the guesses of previous informants. Participants revised
their judgments based on this information, but generally gave equal
weight to independent and sequential testimony. A notable exception was
when individuals were separated out by their general beliefs in the
value of independent over dependent information. Those who saw
independent information as more valuable, gave more weight to
independent testimony in the judgment task. We discuss the implications
for Bayesian models of judgment using social information.*

I really liked this, a non result was shown to be due to the aggregation
of two different sub groups in the population that had opposing views of
what information independant vs sequential data points give.

#### 1084 - Using Systems Factorial Technology to Determine the Fundamental Cognitive Properties of Decision Making.

*Most decisions depend on multiple sources of information and a number
of models have been posited to explain how people combine those sources
as part of the decision-making process. These models range from those
based on heuristics, such as a “take-the-best” heuristic, to those based
on probabilistic inference, such as those based on naïve Bayesian
inferences. Unfortunately, choice probabilities are often not sufficient
to distinguish among these models. In the current work, we will describe
how systems factorial technology (SFT), a response time based approach
used in perception research, can be applied to discriminate among
candidate decision-making models. We demonstrate a framework for
estimating the SFT statistics and independently manipulating the cue
validities, while controlling the conditional probabilities associated
with each information source. We present results from a perceptual
decision-making study with environments that either encourage using
multiple cues or are more neutral and discuss the implications for
decision-making models.*

Nice application of SFT to decision making, in this case in probabilitic
inference, using an approach that seems quite familiar. Might be nice to
reach out to Cara via <zinn.10@wright.edu>

#### 2066 - Blast from the Past…Stroop Interference & Aging.

*The Stroop task is regarded as the “gold standard” for assessing
attentional control, however, processing speed differences between age
groups complicates age by congruency interactions. Several Brinley
meta-analyses (based on group means) have indicated that there is no
effect of age on Stroop interference above and beyond general slowing.
In the present study, we investigated the Stroop effect in younger and
older adults using data from 29 experiments from different labs, and
Universities. All datasets came from computerized, color-naming Stroop
tasks with trial-level data for congruent and incongruent trials. We
examined age differences in the Stroop effect by controlling for general
slowing in several ways. First, trial-level response latencies were
z-scored based on each individual’s mean response latency and standard
deviation. Second, we calculated a proportion score dividing each
participant’s Stroop effect by their mean incongruent response time.
Third, we performed a linear mixed-effect analysis allowing the
intercept to vary randomly for each participant. All three approaches
yielded a highly reliable disproportionate Stroop effect in older adults
compared to younger adults, after controlling for general slowing.*

Nice work and nicely presented investigation of age effects on stroop
responses. Could be a good dataset, maybe reach out to the authors.
(j.nicosia@wustl.edu and <ecohensh@wustl.edu>) (Dataset is trial level
stroop data for a number of experiments).

#### 2102 - Response Time Modeling for the Size Congruity Effect: Early vs Late Interaction.

*The size-congruity effect (SCE) occurs when numerical magnitude
interferes with judgments of physical size. This interference is either
occurs in the encoding-related or decision-related stages. To
discriminate between these accounts, we used a class of mathematical
models (ex-Wald, shifted Wald & EZ-Diffusion) to index the underlying
cognitive processes via estimates of drift rate, response threshold, and
nondecision time. We manipulated congruity in a single-digit physical
comparison task and measured RTs. First, we found that congruent trials
were processed faster than incongruent trials, which is indicative of
the SCE. Next, via the mathematical models, we found that the drift rate
for incongruent trials was smaller than for congruent trials, indicating
that incongruent trials had a faster rate of information uptake. The
response threshold for incongruent trials was larger than for congruent
trials, indicating that for incongruent trials more information needed
to be accumulated before responding. Critically, there was no difference
for nondecision time between trial type. This combination of results
provide support for a late interaction account of the SCE, which sheds
light onto decision-related models of number processing.*

Kristen Bowman, Tarleton State University (kbowman@tarleton.edu) with
Thomas Faulkenberry

Nice talk on the investigation of processing characteristics in
size-congruity effects for numerical judgements. Wonder whether there
would be data that could be investigated using SFT like methods to view
parallel vs coactive processing.

#### 2151 - Modeling Adaptive Reasoning in Rock, Paper, Scissors.

*Human conflict and coordination relies on our ability to predict the
behavior of others across a range of settings. We investigate how people
adapt to their opponents in repeated adversarial interactions through
iterated play of Rock, Paper, Scissors (RPS). Participants (N=217)
played 300 rounds of RPS against bots employing seven stable strategies
that parametrically varied the source and complexity of their behavioral
regularities. We show that both the time course and the extent to which
people detect patterned opponent behavior varies with the complexity of
the bot’s strategy. We model participants’ learning trajectories as
maximizing the expected value of chosen moves subject to different
possible opponent strategies. We find that our experimental data cannot
be accounted for by learning over any single representational schema.
Instead, our results suggest that participants aggregate multiple models
differing in their representations of opponent decision making. These
results provide novel insights into the precise means by which people
detect patterns in others’ behavior over repeated interactions, an
ability that is key to predicting what people will do next in
cooperative and competitive environments.*

Ed Vul Erik Brockbank, University of California, San Diego

Nice work, like how the pattern of responses for the model are
illustrated against the pattern of subjects responses, showing different
levels of the model and how they do not capute all peoples patterns.

#### 3217 - The Importance of a Team Science Approach in Psychological Research: The Psychological Science Accelerator.

*As research over the past decade has stressed issues surrounding
replication challenges within psychological research, many have
highlighted insufficient statistical power, the need for more open and
transparent research practices, as well as more globally representative
samples. In their seminal paper, Henrich, Heine, and Norenzayan (2009)
reported that “96% of psychological samples come from countries with
only 12% of the world’s population,” populations often referred to as
WEIRD (Western, educated, industrialized, rich, and democratic). In an
effort to address these challenges, the Psychological Science
Accelerator (PSA), the largest distributed network of laboratories, was
designed to support crowdsourced research projects focused on diverse
samples and open science practices. Currently, the PSA consists of more
than 500 laboratories representing 70+ countries across six continents.
This democratic and crowdsourced approach to psychological science has
the potential to advance the study of human behavior in important ways,
through rigor, transparency, and with greater representation from
diverse populations. Successes and challenges of a large-scale team
science approach to psychological science will be examined.*

Interesting proposal, will check out their website and see what it is
about.

#### 3245 - The Adaptive Role of Recency in Dynamic Decision Environments.

*Decision-making environments faced by humans (and other animals) are
typically autocorrelated and dynamic (e.g., resource patches that extend
and change in space and time). Researchers have proposed that recency
biases in human memory are adaptations to such environmental
structures—in such environments, averaging across all previously
experienced outcomes can eliminate useful information that is predictive
of future states. Here we explore the influence of such recency effects
in human sequential decision making and investigate the role of
working-memory capacity in mediating recency. We expected working-memory
limits to amplify adaptive recency effects by narrowing the window of
experience included in decision making. We compared recency-based choice
behavior in a static structure (where probabilities of choice outcomes
remaining constant across time) with choices in a dynamic,
autocorrelated structure (where outcome probabilities changed gradually
or abruptly). Computational modelling revealed strong recency effects,
but an inconclusive role of working-memory capacity in producing them.*

Peter Todd Mahi Luthra, Indiana University - Bloomington

Interesting descriptive? model of how recency effect decision making
under uncertainty in a prediction task in the context of differing
strucutre for the environment, specifically where the probability
structure between the two choices changes (or remains static) in
different ways.

#### 3246 - Evidence Integration and Confidence Are Modulated by Stimulus Consistency.

*Evidence-integration is a normative decision algorithm for alternatives
with noisy evidence, which has been successful in accounting for a vast
amount of behavioral and neural data. Here, using a novel model-free
behavioral method, we monitor the decision boundary, and reveal
integration to a collapsing-boundary in data from two experiments (with
numerical and perceptual evidence). Second, we find that the shape of
the boundary varies with the consistency of the evidence and find
support for a mechanism in which incoming samples are modulated based on
their consistency with previous ones. To test this mechanism, we
conducted an additional experiment, in which stimulus-consistency is
manipulated independently from the total evidence. The results confirm
the model, showing that both accuracy and decision confidence are
modulated by stimulus-consistency, indicating a new type of within trial
confirmation-bias. Finally, we show that this bias has the benefit of
making the decision more robust to non-encoding noise.*

Marius Usher Rani Moran, University College London Moshe Glickman, Tel
Aviv University

Interesting work on the stimulus consistency bias, check out "Evidence
Integration and decision-confidence are modulated by stimulus
consistency" (Bioarxiv) (and mendeley)

#### 3259 - A Failure of the Selective Influence Assumption Underlying Theories of Human Response Time.

*A universal assumption in human behavioral research is that response
time can be divided into a series of sequential stages that perform
different computations. This assumption implies selective influence of
experimental factors on stage durations. For instance, manipulations of
perceptual difficulty should affect perception and decision stages but
not the motor stage. We tested this assumption by recording the
electromyography of response agonists in a paradigmatic perceptual
decision task, the random dot motion task, which allowed us to measure
premotor time (PMT) and motor time (MT) on single trials. We found that
PMT and MT substantially increased with perceptual difficulty. In
addition, we observed covert motor activity during the decision process
that reflected the ongoing uncertainty of the decision. These findings
reveal a violation of selective influence and suggest an alternative
conception of human information processing involving parallel and
interactive cognitive and sensorimotor states.*

Nathan Evans Thibault Gajdos, Aix-Marseille University Gordon Logan,
Vanderbilt University Mathieu Servant, University of Franche-Comté

Eh - not too impressed by this work - would have to look into it but it
seems strange to me that there are 2 boundaries in this way.

#### 3320 - Intentional Binding: An Unintentional Artifact?

*Intentional Binding (IB) is typically regarded as an implicit measure
of the sense of agency (SoA) itself a core aspect of our mental lives.
Given the fundamental nature of SoA, one would expect IB to be present
at the individual level. To find out, we compared aggregate vs.
individual data in an experimental study and in a publicly available
dataset. Aggregate results replicated the expected directionality for
action and outcome binding in both studies. However, individual-level
analyses revealed that almost half of the participants in our study
(N=15/35) and half of the participants in the public dataset (N=10/20)
had mean binding values for either action or outcome that were in the
opposite of the expected direction, in line with results from
involuntary action conditions. These findings raise serious
methodological and theoretical concerns for the study of IB. More
importantly, they call into question the very nature of the phenomenon
itself.*

Pernille Hemmer Julien Musolino Laura Saad, Rutgers University - New
Brunswick

Interesting look at what is coming to be a regular story. Literature
says one thing (effect exists) but gfenerally only reports aggregate
data, researcher looks at individual results and sees that there is more
variability than reported. Intertesting dataset in Borhani, Beck and
Haggard (2017)

### Statistics and Methodology

#### Outliers Among Us: How to Identify and Deal with Extreme Data Points

Just a poster (no talk), in Mendeley now, useful refs for outlier
detection
