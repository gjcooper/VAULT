---
cssclass: research_note
type: "journalArticle"
author: "Eckstein, Maria K.; Collins, Anne G. E."
title: "Computational evidence for hierarchically structured reinforcement learning in humans"
publication: "Proceedings of the National Academy of Sciences"
date: 2020-11-24
citekey: eckstein2020computational
aliases: 
    - "Computational evidence for hierarchically structured reinforcement learning in humans"
---

# Computational evidence for hierarchically structured reinforcement learning in humans

Eckstein, M. K., & Collins, A. G. E. (2020). Computational evidence for hierarchically structured reinforcement learning in humans. _Proceedings of the National Academy of Sciences_, _117_(47), 29381–29389. [https://doi.org/10.1073/pnas.1912330117](https://doi.org/10.1073/pnas.1912330117)
[online](http://zotero.org/users/7162438/items/JYQGPV6R) [local](zotero://select/library/items/JYQGPV6R) [pdf](file:///home/gjc216/Zotero/storage/KD5IE5I7/Eckstein%20and%20Collins%20-%202020%20-%20Computational%20evidence%20for%20hierarchically%20structur.pdf)
 [pdf](file:///home/gjc216/Zotero/storage/RVUSR9EJ/Eckstein%20and%20Collins%20-%202020%20-%20Computational%20evidence%20for%20hierarchically%20structured%20reinforcement%20learning%20in%20humans.pdf)
 

 
%% begin notes %%

## My Thoughts


%% end notes %%

### Annotations

%% begin annotations %%

##### Imported on 2024-08-19 2:35 pm
>[!quote|#5fb236]
>Because marginal model likelihoods were intractable, we approximated them using simulations, similar to refs. 42, 47, and 48. [(p. 29386)](zotero://open-pdf/library/items/KD5IE5I7?page=29386&annotation=VYXNRDJY)

---
>[!quote|#ffd400]
>Using the notations introduced in Results, values were updated based on Qt+1(a|s, c) = Qt(a|s, c) + α (r − Qt (a|s, c)), and actions were selected based on p(a|s, c) = exp(Q(a|s,c))  ∑  ai exp(β Q(ai |s,c)) . [(p. 29388)](zotero://open-pdf/library/items/KD5IE5I7?page=29388&annotation=23MAJ8P3)

---
>[!quote|#ffd400]
>The forgetting parameters f ∈ [fa, fTS] captured value decay in both models: Qt+1 = (1 − f ) Qt + f Qinit . [(p. 29388)](zotero://open-pdf/library/items/KD5IE5I7?page=29388&annotation=7I8JQFMV)

---
>[!quote|#ffd400]
>The hierarchical Bayes model also learned task-sets but acquired their action-values based on correct–incorrect rather than continuous feedback: Qt+1(a|s, TS) = Qt(a|s, TS) + α (correct − Qt(a|s, TS)). [(p. 29388)](zotero://open-pdf/library/items/KD5IE5I7?page=29388&annotation=69RN4T3I)

---%% end annotations %%

## Item Notes

#### Tags

##### Keywords

#subject/priority1

##### Authors

[[Maria K. Eckstein]] [[Anne G. E. Collins]]

##### Publication

#pub/proc._natl._acad._sci._u.s.a.


%% Import Date: 2024-08-19T14:35:39.457+10:00 %%
