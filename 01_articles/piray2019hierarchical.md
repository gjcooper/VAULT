---
cssclasses:
  - research_note
type: journalArticle
author: Piray, Payam; Dezfouli, Amir; Heskes, Tom; Frank, Michael J.; Daw, Nathaniel D.
title: Hierarchical Bayesian inference for concurrent model fitting and comparison for group studies
publication: PLOS Computational Biology
date: 2019-06-18
citekey: piray2019hierarchical
aliases:
  - Hierarchical Bayesian inference for concurrent model fitting and comparison for group studies
---

# Hierarchical Bayesian inference for concurrent model fitting and comparison for group studies

Piray, P., Dezfouli, A., Heskes, T., Frank, M. J., & Daw, N. D. (2019). Hierarchical Bayesian inference for concurrent model fitting and comparison for group studies. _PLOS Computational Biology_, _15_(6), e1007043. [https://doi.org/10.1371/journal.pcbi.1007043](https://doi.org/10.1371/journal.pcbi.1007043)
[online](http://zotero.org/users/7162438/items/8TVZVK4X) [local](zotero://select/library/items/8TVZVK4X) [pdf](file:///home/gjc216/Zotero/storage/7HTTLGHF/Piray%20et%20al.%20-%202019%20-%20Hierarchical%20Bayesian%20inference%20for%20concurrent%20mod.pdf)
 

 
%% begin notes %%

## My Thoughts

This seems like a nice approach, and shares some philosophical similarities to my [[Architecture of MultiAttribute Choice]] paper (but not methodological similarities). Some good explanations of [[Exceedance probability]] and [[model responsibility]]. There is a MATLAB package based on this work, which is known as [CBM](https://github.com/payampiray/cbm). CBM is a package in a very loose definition, more a collection of MATLAB scripts, but it is something that [[Joseph Barnby]] and team has used in the past.

Under the hood the Hierarchical Bayesian Inference is using [[Variational Bayes]] for parameter estimation, using model responsibility to build the group level distribution for each model. I believe the influence on the group distribution by each participant is driven by the model responsibility for that model and subject.

This allows inference between models, groups parameter distributions and random effects simultaneously.

%% end notes %%

### Annotations

%% begin annotations %%

##### Imported on 2024-07-31 1:51 pm
>[!quote|#ffd400]
>Although HPE characterizes variation across subjects in the model parameters hkn (that is, ittreats those parameters as random effects), acritical assumption of the procedure isthat the parameters for model k are estimated assuming that the same model isresponsible for generating data in all subjects. [(p. 4)](zotero://open-pdf/library/items/7HTTLGHF?page=4&annotation=349WLLPG)

---
>[!quote|#5fb236]
>the HBI method estimates the probability of each subjectâ€™s dataset being generated by each model, or the responsibility of model k for generating data for subject n, rkn, which isexpressed as (expected) probability [(p. 5)](zotero://open-pdf/library/items/7HTTLGHF?page=5&annotation=IL3SZEGK)

---
>[!quote|#5fb236]
>researchers are interested in selecting asingle best model (rather than relative comparisons among several) even in the face of variation in model identity across subjects. One way to accomplish this goal isto compute the exceedance probability of each candidate model, ametric commonly used for model selection [13] [(p. 5)](zotero://open-pdf/library/items/7HTTLGHF?page=5&annotation=J8PF2E8Q)

---%% end annotations %%

## Item Notes

#### Tags

##### Keywords

#subject/decision_making #subject/algorithms #subject/learning #subject/simulation_and_modeling #subject/normal_distribution #subject/kalman_filter #subject/parkinson_disease #subject/statistical_distributions

##### Authors

[[Payam Piray]] [[Amir Dezfouli]] [[Tom Heskes]] [[Michael J. Frank]] [[Nathaniel D. Daw]]

##### Publication

#pub/plos_computational_biology


%% Import Date: 2024-07-31T13:51:40.006+01:00 %%
